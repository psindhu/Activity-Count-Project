{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold Percent: 49.14154664223998\n",
      "Threshold Low Pass Percent: 80.74873381771063\n",
      "Fourier Percent: 78.4257275453\n",
      "finished\n",
      "Check CompleteResults.csv in Accelerometer Data folder\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import sys\n",
    "from math import *\n",
    "from matplotlib import *\n",
    "import numpy as np\n",
    "from scipy import *\n",
    "import scipy.signal as signal\n",
    "import scipy.ndimage as ndimage\n",
    "import matplotlib.pyplot as mp\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os.path\n",
    "import time as tm\n",
    "from statistics import mean, stdev\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def zero_cross(x_arr, y_arr, filt):\n",
    "    #Find zero-cross line\n",
    "    ymax = max(y_arr)\n",
    "    ymin = min(y_arr)\n",
    "    alpha = 0.65\n",
    "    zero_cross = alpha * (ymax-ymin) + ymin\n",
    "    \n",
    "    #Zero-Crossing Detection Algorithm\n",
    "    step_counter = 0\n",
    "    i = 1\n",
    "    last = 0\n",
    "    while i < len(y_arr):\n",
    "        if float(y_arr[i]) > zero_cross and float(y_arr[i-1]) < zero_cross:\n",
    "            if(filt == True):\n",
    "                step_counter += 1\n",
    "            elif(filt == False):\n",
    "                if(float(x_arr[i]) > (last + .3)):\n",
    "                    step_counter += 1\n",
    "                    last = x_arr[i]\n",
    "#                 print(step_counter)\n",
    "        i += 1\n",
    "    return step_counter\n",
    "\n",
    "def fourier_transform(time, mag):\n",
    "    \n",
    "    magfft=np.fft.fft(magf, n=None, axis=-1)\n",
    "    Ps=np.abs(magfft)**2\n",
    "        \n",
    "    time_step = time[len(time)-1]/(len(magfft)-1)\n",
    "    freqs = np.fft.fftfreq(len(mag), time_step)\n",
    "    idx = np.argsort(freqs)\n",
    "    idxx = np.argsort(Ps[idx])\n",
    "\n",
    "    freqsIdx = freqs[idx]\n",
    "    psIdx = Ps[idx]\n",
    "    freqsPos = []\n",
    "    psPos = []\n",
    "    i = 0\n",
    "    while (i < len(freqsIdx)):\n",
    "        if freqsIdx[i] > 0 and freqsIdx [i] < 2:\n",
    "            freqsPos.append(freqsIdx[i])\n",
    "            psPos.append(psIdx[i])\n",
    "        i = i + 1\n",
    "    c1=(time[len(time)-1]*np.abs(freqs[idx][idxx[len(idxx)-1]]))\n",
    "    return c1\n",
    "\n",
    "# Put the file name into correct array\n",
    "def categorize_files(filesArray):\n",
    "    for person in filesArray:\n",
    "        for file in person:\n",
    "            if \"arm\" in file:\n",
    "                armFiles.append(file)\n",
    "            elif \"bridge\" in file:\n",
    "                bridgeFiles.append(file)\n",
    "            elif \"bicep\" in file:\n",
    "                bicepFiles.append(file)\n",
    "            elif \"crunch\" in file:\n",
    "                crunchFiles.append(file)\n",
    "            elif \"elbow\" in file:\n",
    "                elbowFiles.append(file)\n",
    "            elif \"lift\" in file:\n",
    "                liftFiles.append(file)\n",
    "            elif \"lunge\" in file:\n",
    "                lungeFiles.append(file)\n",
    "            elif \"pushup\" in file:\n",
    "                pushupFiles.append(file)\n",
    "            elif \"squat\" in file:\n",
    "                squatFiles.append(file)\n",
    "            elif \"upper\" in file:\n",
    "                upperFiles.append(file)\n",
    "\n",
    "# Return which person the file is from\n",
    "def getPerson(file):\n",
    "    if \"S10\" in file:\n",
    "        return \"S10\"\n",
    "    elif \"S11\" in file:\n",
    "        return \"S11\"\n",
    "    elif \"S12\" in file:\n",
    "        return \"S12\"\n",
    "    elif \"S13\" in file:\n",
    "        return \"S13\"\n",
    "    elif \"S14\" in file:\n",
    "        return \"S14\"\n",
    "    elif \"S15\" in file:\n",
    "        return \"S15\"\n",
    "    elif \"S16\" in file:\n",
    "        return \"S16\"\n",
    "    elif \"S17\" in file:\n",
    "        return \"S17\"\n",
    "    elif \"S18\" in file:\n",
    "        return \"S18\"\n",
    "    elif \"S1\" in file:\n",
    "        return \"S1\"\n",
    "    elif \"S2\" in file:\n",
    "        return \"S2\"\n",
    "    elif \"S3\" in file:\n",
    "        return \"S3\"\n",
    "    elif \"S4\" in file:\n",
    "        return \"S4\"\n",
    "    elif \"S5\" in file:\n",
    "        return \"S5\"\n",
    "    elif \"S6\" in file:\n",
    "        return \"S6\"\n",
    "    elif \"S7\" in file:\n",
    "        return \"S7\"\n",
    "    elif \"S8\" in file:\n",
    "        return \"S8\"\n",
    "    elif \"S9\" in file:\n",
    "        return \"S9\"\n",
    "\n",
    "#Accelerometer data for each person\n",
    "# Copied from File Array Creator\n",
    "S1 = ['acc_S1arm1_0t.csv', 'acc_S1arm2_0t.csv', 'acc_S1bicep1_0t.csv', 'acc_S1bicep2_0t.csv', 'acc_S1bridge1_0t.csv', 'acc_S1bridge2_0t.csv', 'acc_S1crunch1_0t.csv', 'acc_S1crunch2_0t.csv', 'acc_S1elbow1_0t.csv', 'acc_S1elbow2_0t.csv', 'acc_S1lift1_0t.csv', 'acc_S1lift2_0t.csv', 'acc_S1lunge1_0t.csv', 'acc_S1lunge2_0t.csv', 'acc_S1pushup1_0t.csv', '', 'acc_S1squat1_0t.csv', 'acc_S1squat2_0t.csv', 'acc_S1upper1_0t.csv', 'acc_S1upper2_0t.csv']\n",
    "S2 = ['acc_S2arm1_0t.csv', 'acc_S2arm2_0t.csv', 'acc_S2bicep1_0t.csv', 'acc_S2bicep2_0t.csv', 'acc_S2bridge1_0t.csv', 'acc_S2bridge2_0t.csv', 'acc_S2crunch1_0t.csv', 'acc_S2crunch2_0t.csv', 'acc_S2elbow1_0t.csv', 'acc_S2elbow2_0t.csv', 'acc_S2lift1_0t.csv', 'acc_S2lift2_0t.csv', 'acc_S2lunge1_0t.csv', 'acc_S2lunge2_0t.csv', 'acc_S2pushup1_0t.csv', '', 'acc_S2squat1_0t.csv', 'acc_S2squat2_0t.csv', 'acc_S2upper1_0t.csv', 'acc_S2upper2_0t.csv']\n",
    "S3 = ['acc_S3arm1_0t.csv', 'acc_S3arm2_0t.csv', 'acc_S3bicep1_0t.csv', 'acc_S3bicep2_0t.csv', 'acc_S3bridge1_0t.csv', 'acc_S3bridge2_0t.csv', 'acc_S3crunch1_0t.csv', 'acc_S3crunch2_0t.csv', 'acc_S3elbow1_0t.csv', 'acc_S3elbow2_0t.csv', 'acc_S3lift1_0t.csv', 'acc_S3lift2_0t.csv', 'acc_S3lunge1_0t.csv', 'acc_S3lunge2_0t.csv', 'acc_S3pushup1_0t.csv', 'acc_S3pushup2_0t.csv', 'acc_S3squat1_0t.csv', 'acc_S3squat2_0t.csv', '', 'acc_S3upper2_0t.csv']\n",
    "S4 = ['acc_S4arm1_0t.csv', 'acc_S4arm2_0t.csv', 'acc_S4bicep1_0t.csv', 'acc_S4bicep2_0t.csv', 'acc_S4bridge1_0t.csv', 'acc_S4bridge2_0t.csv', 'acc_S4crunch1_0t.csv', 'acc_S4crunch2_0t.csv', 'acc_S4elbow1_0t.csv', 'acc_S4elbow2_0t.csv', 'acc_S4lift1_0t.csv', 'acc_S4lift2_0t.csv', 'acc_S4lunge1_0t.csv', 'acc_S4lunge2_0t.csv', 'acc_S4pushup1_0t.csv', 'acc_S4pushup2_0t.csv', '', 'acc_S4squat2_0t.csv', 'acc_S4upper1_0t.csv', 'acc_S4upper2_0t.csv']\n",
    "S5 = ['acc_S5arm1_0t.csv', 'acc_S5arm2_0t.csv', 'acc_S5bicep1_0t.csv', 'acc_S5bicep2_0t.csv', 'acc_S5bridge1_0t.csv', 'acc_S5bridge2_0t.csv', 'acc_S5crunch1_0t.csv', 'acc_S5crunch2_0t.csv', 'acc_S5elbow1_0t.csv', 'acc_S5elbow2_0t.csv', 'acc_S5lift1_0t.csv', 'acc_S5lift2_0t.csv', 'acc_S5lunge1_0t.csv', 'acc_S5lunge2_0t.csv', 'acc_S5pushup1_0t.csv', 'acc_S5pushup2_0t.csv', 'acc_S5squat1_0t.csv', 'acc_S5squat2_0t.csv', 'acc_S5upper1_0t.csv', 'acc_S5upper2_0t.csv']\n",
    "S6 = ['acc_S6arm1_0t.csv', 'acc_S6arm2_0t.csv', 'acc_S6bicep1_0t.csv', 'acc_S6bicep2_0t.csv', 'acc_S6bridge1_0t.csv', 'acc_S6bridge2_0t.csv', 'acc_S6crunch1_0t.csv', 'acc_S6crunch2_0t.csv', 'acc_S6elbow1_0t.csv', 'acc_S6elbow2_0t.csv', 'acc_S6lift1_0t.csv', 'acc_S6lift2_0t.csv', 'acc_S6lunge1_0t.csv', 'acc_S6lunge2_0t.csv', 'acc_S6pushup1_0t.csv', 'acc_S6pushup2_0t.csv', 'acc_S6squat1_0t.csv', 'acc_S6squat2_0t.csv', 'acc_S6upper1_0t.csv', 'acc_S6upper2_0t.csv']\n",
    "S7 = ['acc_S7arm1_0t.csv', 'acc_S7arm2_0t.csv', 'acc_S7bicep1_0t.csv', 'acc_S7bicep2_0t.csv', 'acc_S7bridge1_0t.csv', 'acc_S7bridge2_0t.csv', 'acc_S7crunch1_0t.csv', 'acc_S7crunch2_0t.csv', 'acc_S7elbow1_0t.csv', 'acc_S7elbow2_0t.csv', 'acc_S7lift1_0t.csv', 'acc_S7lift2_0t.csv', 'acc_S7lunge1_0t.csv', 'acc_S7lunge2_0t.csv', 'acc_S7pushup1_0t.csv', 'acc_S7pushup2_0t.csv', 'acc_S7squat1_0t.csv', 'acc_S7squat2_0t.csv', 'acc_S7upper1_0t.csv', 'acc_S7upper2_0t.csv']\n",
    "S8 = ['acc_S8arm1_0t.csv', 'acc_S8arm2_0t.csv', 'acc_S8bicep1_0t.csv', 'acc_S8bicep2_0t.csv', 'acc_S8bridge1_0t.csv', 'acc_S8bridge2_0t.csv', 'acc_S8crunch1_0t.csv', 'acc_S8crunch2_0t.csv', 'acc_S8elbow1_0t.csv', 'acc_S8elbow2_0t.csv', 'acc_S8lift1_0t.csv', 'acc_S8lift2_0t.csv', 'acc_S8lunge1_0t.csv', 'acc_S8lunge2_0t.csv', 'acc_S8pushup1_0t.csv', 'acc_S8pushup2_0t.csv', 'acc_S8squat1_0t.csv', 'acc_S8squat2_0t.csv', 'acc_S8upper1_0t.csv', 'acc_S8upper2_0t.csv']\n",
    "S9 = ['', 'acc_S9arm2_0t.csv', 'acc_S9bicep1_0t.csv', 'acc_S9bicep2_0t.csv', 'acc_S9bridge1_0t.csv', 'acc_S9bridge2_0t.csv', 'acc_S9crunch1_0t.csv', '', 'acc_S9elbow1_0t.csv', 'acc_S9elbow2_0t.csv', 'acc_S9lift1_0t.csv', 'acc_S9lift2_0t.csv', 'acc_S9lunge1_0t.csv', 'acc_S9lunge2_0t.csv', 'acc_S9pushup1_0t.csv', 'acc_S9pushup2_0t.csv', 'acc_S9squat1_0t.csv', 'acc_S9squat2_0t.csv', 'acc_S9upper1_0t.csv', 'acc_S9upper2_0t.csv']\n",
    "S10 = ['acc_S10arm1_0t.csv', 'acc_S10arm2_0.csv', 'acc_S10bicep1_0.csv', 'acc_S10bicep2_0.csv', 'acc_S10bridge1_0.csv', 'acc_S10bridge2_0.csv', 'acc_S10crunch1_0.csv', 'acc_S10crunch2_0.csv', 'acc_S10elbow1_0.csv', 'acc_S10elbow2_0.csv', 'acc_S10lift1_0.csv', 'acc_S10lift2_0.csv', '', 'acc_S10lunge2_0.csv', '', '', 'acc_S10squat1_0.csv', 'acc_S10squat2_0.csv', 'acc_S10upper1_0.csv', '']\n",
    "S11 = ['', 'acc_S11arm2_0.csv', 'acc_S11bicep1_0.csv', 'acc_S11bicep2_0.csv', 'acc_S11bridge1_0.csv', 'acc_S11bridge2_0.csv', 'acc_S11crunch1_0.csv', 'acc_S11crunch2_0.csv', 'acc_S11elbow1_0.csv', 'acc_S11elbow2_0.csv', 'acc_S11lift1_0.csv', 'acc_S11lift2_0.csv', 'acc_S11lunge1_0.csv', 'acc_S11lunge2_0.csv', 'acc_S11pushup1_0.csv', 'acc_S11pushup2_0.csv', 'acc_S11squat1_0.csv', 'acc_S11squat2_0.csv', 'acc_S11upper1_0.csv', 'acc_S11upper2_0.csv']\n",
    "S12 = ['acc_S12arm1_0.csv', 'acc_S12arm2_0.csv', 'acc_S12bicep1_0.csv', 'acc_S12bicep2_0.csv', 'acc_S12bridge1_0.csv', 'acc_S12bridge2_0.csv', 'acc_S12crunch1_0.csv', 'acc_S12crunch2_0.csv', 'acc_S12elbow1_0.csv', 'acc_S12elbow2_0.csv', 'acc_S12lift1_0.csv', 'acc_S12lift2_0.csv', 'acc_S12lunge1_0.csv', 'acc_S12lunge2_0.csv', 'acc_S12pushup1_0.csv', '', 'acc_S12squat1_0.csv', 'acc_S12squat2_0.csv', 'acc_S12upper1_0.csv', 'acc_S12upper2_0.csv']\n",
    "S13 = ['acc_S13arm1_0.csv', 'acc_S13arm2_0.csv', 'acc_S13bicep1_0.csv', 'acc_S13bicep2_0.csv', 'acc_S13bridge1_0.csv', 'acc_S13bridge2_0.csv', 'acc_S13crunch1_0.csv', 'acc_S13crunch2_0.csv', 'acc_S13elbow1_0.csv', 'acc_S13elbow2_0.csv', 'acc_S13lift1_0.csv', 'acc_S13lift2_0.csv', '', 'acc_S13lunge2_0.csv', 'acc_S13pushup1_0.csv', 'acc_S13pushup2_0.csv', 'acc_S13squat1_0.csv', 'acc_S13squat2_0.csv', 'acc_S13upper1_0.csv', 'acc_S13upper2_0.csv']\n",
    "S14 = ['acc_S14arm1_0.csv', 'acc_S14arm2_0.csv', 'acc_S14bicep1_0.csv', 'acc_S14bicep2_0.csv', 'acc_S14bridge1_0.csv', 'acc_S14bridge2_0.csv', 'acc_S14crunch1_0.csv', 'acc_S14crunch2_0.csv', 'acc_S14elbow1_0.csv', 'acc_S14elbow2_0.csv', 'acc_S14lift1_0.csv', 'acc_S14lift2_0.csv', 'acc_S14lunge1_0.csv', 'acc_S14lunge2_0.csv', 'acc_S14pushup1_0.csv', 'acc_S14pushup2_0.csv', 'acc_S14squat1_0.csv', 'acc_S14squat2_0.csv', 'acc_S14upper1_0.csv', 'acc_S14upper2_0.csv']\n",
    "S15 = ['acc_S15arm1_0.csv', 'acc_S15arm2_0.csv', 'acc_S15bicep1_0.csv', 'acc_S15bicep2_0.csv', 'acc_S15bridge1_0.csv', 'acc_S15bridge2_0.csv', 'acc_S15crunch1_0.csv', 'acc_S15crunch2_0.csv', 'acc_S15elbow1_0.csv', 'acc_S15elbow2_0.csv', 'acc_S15lift1_0.csv', 'acc_S15lift2_0.csv', 'acc_S15lunge1_0.csv', 'acc_S15lunge2_0.csv', 'acc_S15pushup1_0.csv', 'acc_S15pushup2_0.csv', 'acc_S15squat1_0.csv', 'acc_S15squat2_0.csv', 'acc_S15upper1_0.csv', 'acc_S15upper2_0.csv']\n",
    "S16 = ['acc_S16arm1_0.csv', 'acc_S16arm2_0.csv', 'acc_S16bicep1_0.csv', 'acc_S16bicep2_0.csv', 'acc_S16bridge1_0.csv', 'acc_S16bridge2_0.csv', 'acc_S16crunch1_0.csv', 'acc_S16crunch2_0.csv', 'acc_S16elbow1_0.csv', 'acc_S16elbow2_0.csv', 'acc_S16lift1_0.csv', 'acc_S16lift2_0.csv', 'acc_S16lunge1_0.csv', 'acc_S16lunge2_0.csv', '', '', 'acc_S16squat1_0.csv', 'acc_S16squat2_0.csv', 'acc_S16upper1_0.csv', 'acc_S16upper2_0.csv']\n",
    "S17 = ['acc_S17arm1_0.csv', 'acc_S17arm2_0.csv', 'acc_S17bicep1_0.csv', 'acc_S17bicep2_0.csv', 'acc_S17bridge1_0.csv', 'acc_S17bridge2_0.csv', 'acc_S17crunch1_0.csv', 'acc_S17crunch2_0.csv', 'acc_S17elbow1_0.csv', 'acc_S17elbow2_0.csv', 'acc_S17lift1_0.csv', 'acc_S17lift2_0.csv', 'acc_S17lunge1_0.csv', 'acc_S17lunge2_0.csv', 'acc_S17pushup1_0.csv', 'acc_S17pushup2_0.csv', 'acc_S17squat1_0.csv', 'acc_S17squat2_0.csv', 'acc_S17upper1_0.csv', 'acc_S17upper2_0.csv']\n",
    "S18 = ['acc_S18arm1_0.csv', 'acc_S18arm2_0.csv', 'acc_S18bicep1_0.csv', 'acc_S18bicep2_0.csv', 'acc_S18bridge1_0.csv', 'acc_S18bridge2_0.csv', 'acc_S18crunch1_0.csv', 'acc_S18crunch2_0.csv', 'acc_S18elbow1_0.csv', 'acc_S18elbow2_0.csv', 'acc_S18lift1_0.csv', 'acc_S18lift2_0.csv', 'acc_S18lunge1_0.csv', 'acc_S18lunge2_0.csv', '', 'acc_S18pushup2_0.csv', 'acc_S18squat1_0.csv', 'acc_S18squat2_0.csv', 'acc_S18upper1_0.csv', 'acc_S18upper2_0.csv']\n",
    "subdirectories = ['S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17', 'S18']\n",
    "filesArray = [S1,S2,S3,S4,S5,S6,S7,S8,S9,S10,S11,S12,S13,S14,S15,S16,S17,S18]\n",
    "\n",
    "#Lists of file names for each exercise\n",
    "armFiles = []\n",
    "bicepFiles = []\n",
    "bridgeFiles = []\n",
    "crunchFiles = []\n",
    "elbowFiles = []\n",
    "liftFiles = []\n",
    "lungeFiles = []\n",
    "pushupFiles = []\n",
    "squatFiles = []\n",
    "upperFiles = []\n",
    "\n",
    "# Lists for exercises and analysis techniques used for looping\n",
    "exerciseList = [\"arm\", \"bicep\", \"bridge\", \"crunch\", \"elbow\", \"lift\", \"lunge\", \"pushup\", \"squat\", \"upper\"]\n",
    "# T is Threshold Crossing\n",
    "# LP is Threshold Crossing with Low Pass Filter\n",
    "# F is Fourier Transform\n",
    "analysisTechniqueList = [\"T\", \"LP\", \"F\"]\n",
    "\n",
    "# Paths\n",
    "mypath = \"Accelerometer Data/\"\n",
    "results = \"Accelerometer Data/CompleteResults.csv\"\n",
    "repetitionsFile = \"Accelerometer Data/Repetitions.csv\"\n",
    "\n",
    "#List of actual repetition counts\n",
    "repetitionsList = []\n",
    "\n",
    "#Dictionary of files and repetitions\n",
    "repetitionsDict = {}\n",
    "\n",
    "#Dictionary of errors\n",
    "errorsDict = {}\n",
    "\n",
    "#Dictionary of average errors\n",
    "RMSEDict = {}\n",
    "\n",
    "#Put the files into correct list\n",
    "categorize_files(filesArray)\n",
    "\n",
    "#Get Repetition Data\n",
    "with open(results, 'w', newline='') as f:\n",
    "    csv_reader = csv.reader(open(repetitionsFile))\n",
    "    for row in csv_reader:\n",
    "        repetitionsList.append(row)\n",
    "        \n",
    "#Put each file name as the key into a dictionary with the repetition count as the value\n",
    "exerciseCount = -1\n",
    "for person in repetitionsList:\n",
    "    exerciseCount = -1\n",
    "    for exerciseRepetition in person:\n",
    "        exerciseCount = exerciseCount + 1\n",
    "        if exerciseRepetition != \"\":\n",
    "            personIndex = repetitionsList.index(person)\n",
    "            name = filesArray[personIndex][exerciseCount]\n",
    "            repetitionsDict[name] = exerciseRepetition\n",
    "            \n",
    "#For each analysis technique\n",
    "for analysisTechnique in range(3):\n",
    "    percentErrorList = []\n",
    "    for file, count in repetitionsDict.items():\n",
    "        person = getPerson(file)\n",
    "        csv_reader = csv.reader(open(mypath + person + '/' + file))\n",
    "        #Get data and find magnitude\n",
    "        verts = []\n",
    "\n",
    "        for row in csv_reader:\n",
    "            verts.append(row)\n",
    "\n",
    "        time = []\n",
    "        mag = []\n",
    "\n",
    "        for vert in verts:\n",
    "            time.append(float(vert[0])-float(verts[0][0]))\n",
    "            mag.append(sqrt(float(vert[1])**2 + float(vert[2])**2 + float(vert[3])**2))\n",
    "            #mag.append(float(vert[3]))\n",
    "\n",
    "        mag= signal.detrend(mag)\n",
    "\n",
    "        #Butterworth Filter\n",
    "        N = 2 #Filter order\n",
    "        fs = (len(mag)-1)/time[len(time)-1]\n",
    "        Wn = 0.01*fs #Cutoff frequency\n",
    "        B, A = signal.butter(N, Wn, output='ba')\n",
    "\n",
    "        magf = signal.filtfilt(B,A, mag)\n",
    "\n",
    "\n",
    "        #Calculate threshold crossing of the data\n",
    "        if analysisTechnique == 0:\n",
    "            #Threshold crossing\n",
    "            c1=zero_cross(time, mag, False)\n",
    "            #Get error from repetition\n",
    "            error = abs(c1 - int(count))\n",
    "            errorsDict[\"T\" + file] = error\n",
    "            percentError = (abs(c1 - int(count))/int(count) * 100)\n",
    "            percentErrorList.append(percentError)\n",
    "        elif analysisTechnique == 1:\n",
    "            #Threshold crossing with low pass\n",
    "            c1=zero_cross(time, magf, True)\n",
    "            #Get error from repetition\n",
    "            error = abs(c1 - int(count))\n",
    "            errorsDict[\"LP\" + file] = error\n",
    "            percentError = (abs(c1 - int(count))/int(count) * 100)\n",
    "            percentErrorList.append(percentError)\n",
    "        elif analysisTechnique == 2:\n",
    "            #Fourier Transform\n",
    "            c1=fourier_transform(time, mag)\n",
    "            #Get error from repetition\n",
    "            error = abs(c1 - int(count))\n",
    "            errorsDict[\"F\" + file] = error\n",
    "            percentError = (abs(c1 - int(count))/int(count) * 100)\n",
    "            percentErrorList.append(percentError)\n",
    "            \n",
    "    #Print error   \n",
    "    if analysisTechnique == 0:\n",
    "        print(\"Threshold Percent: \" + str(100 - mean(percentErrorList)))\n",
    "    elif analysisTechnique == 1:\n",
    "        print(\"Threshold Low Pass Percent: \" + str(100 - mean(percentErrorList)))\n",
    "    elif analysisTechnique == 2:\n",
    "        print(\"Fourier Percent: \" + str(100 - mean(percentErrorList)))\n",
    "    \n",
    "\n",
    "#Get the Root Mean Square Error of each exercise and analysis technique pair\n",
    "for exercise in exerciseList:\n",
    "    for analysisTechnique in analysisTechniqueList:\n",
    "        selectedErrorsList = []\n",
    "        for file, count in errorsDict.items():\n",
    "            if exercise in file:\n",
    "                if analysisTechnique in file:\n",
    "                    selectedErrorsList.append(count*count)\n",
    "        error = sqrt(mean(selectedErrorsList))\n",
    "        RMSEDict[exercise + analysisTechnique] = error\n",
    "        \n",
    "#Get the Root Mean Square Error of exercsies\n",
    "for exercise in exerciseList:\n",
    "    selectedErrorsList = []\n",
    "    for analysisTechnique in analysisTechniqueList:\n",
    "        for file, error in errorsDict.items():\n",
    "            if exercise in file:\n",
    "                if analysisTechnique in file:\n",
    "                    selectedErrorsList.append(error*error)\n",
    "    std = sqrt(mean(selectedErrorsList))\n",
    "    RMSEDict[exercise] = std\n",
    "    \n",
    "#Get the Root Mean Square Error of analysis techniques\n",
    "for analysisTechnique in analysisTechniqueList:\n",
    "    selectedErrorsList = []\n",
    "    for exercise in exerciseList:\n",
    "        for file, error in errorsDict.items():\n",
    "            if exercise in file:\n",
    "                if analysisTechnique in file:\n",
    "                    selectedErrorsList.append(error*error)\n",
    "    std = sqrt(mean(selectedErrorsList))\n",
    "    RMSEDict[analysisTechnique] = std\n",
    "\n",
    "#Write Error Table\n",
    "with open(results, 'w', newline='') as f:\n",
    "    a = csv.writer(f, delimiter=',')\n",
    "    a.writerow([\"Exercise\", \"Threshold\", \"ThresholdWithLowPass\", \"Fourier\", \"RMSE\"])\n",
    "    for exercise in exerciseList:\n",
    "        a.writerow([exercise, RMSEDict[exercise + \"T\"], RMSEDict[exercise + \"LP\"], RMSEDict[exercise + \"F\"], RMSEDict[exercise]])\n",
    "    a.writerow([\"RMSE\", RMSEDict[\"T\"], RMSEDict[\"LP\"], RMSEDict[\"F\"]])\n",
    "        \n",
    "        \n",
    "print(\"finished\")\n",
    "print(\"Check CompleteResults.csv in Accelerometer Data folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
